{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87025aaa",
   "metadata": {},
   "source": [
    "# Train and Save Logistic Regression Model for Research Theme Prediction\n",
    "\n",
    "This notebook trains a logistic regression model to predict research themes based on project titles and saves the trained artifacts for use in the TimeArcs recommendation system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa6a7b23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "# Install required packages if needed\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = ['pandas', 'numpy', 'scikit-learn']\n",
    "for package in packages:\n",
    "    try:\n",
    "        __import__(package.replace('-', '_'))\n",
    "    except ImportError:\n",
    "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', package])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67224efd",
   "metadata": {},
   "source": [
    "## Section 1: Load and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "695e970f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples before filtering: 52\n",
      "Number of unique themes before filtering: 17\n",
      "\n",
      "Theme distribution before filtering:\n",
      "Theme\n",
      "Education & Workforce Development         13\n",
      "Healthcare / Biomedical                    7\n",
      "Software / Systems                         5\n",
      "Cybersecurity                              5\n",
      "AI / Machine Learning                      4\n",
      "Algorithms / Theory / Optimization         3\n",
      "Data / Metadata / Scientific Data          2\n",
      "Environment & Agriculture                  2\n",
      "Energy / Environment                       2\n",
      "Quantum                                    2\n",
      "Blockchain & Privacy                       1\n",
      "Robotics & CPS                             1\n",
      "Disaster / Resilience / Evacuation         1\n",
      "Visualization / Analytics                  1\n",
      "Manufacturing / Advanced Manufacturing     1\n",
      "Sensors / IoT / Edge                       1\n",
      "Networking & Communications                1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "============================================================\n",
      "After filtering themes with < 4 samples:\n",
      "Total samples: 34\n",
      "Number of unique themes: 5\n",
      "\n",
      "Theme distribution after filtering:\n",
      "Theme\n",
      "Education & Workforce Development    13\n",
      "Healthcare / Biomedical               7\n",
      "Software / Systems                    5\n",
      "Cybersecurity                         5\n",
      "AI / Machine Learning                 4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess data\n",
    "df = pd.read_csv('grants_final.tsv', sep='\\t')\n",
    "df = df[['Title', 'Theme']].copy()\n",
    "df = df.drop_duplicates()\n",
    "df = df.dropna()\n",
    "\n",
    "# Clean up the data\n",
    "df['Title'] = df['Title'].str.strip('\"')\n",
    "df['Theme'] = df['Theme'].str.strip(\"'\")\n",
    "\n",
    "print(f\"Total samples before filtering: {len(df)}\")\n",
    "print(f\"Number of unique themes before filtering: {df['Theme'].nunique()}\")\n",
    "\n",
    "# Set threshold for minimum number of samples per theme\n",
    "MIN_SAMPLES_PER_THEME = 4\n",
    "\n",
    "theme_counts = df['Theme'].value_counts()\n",
    "print(f\"\\nTheme distribution before filtering:\\n{theme_counts}\")\n",
    "\n",
    "# Keep only themes with at least MIN_SAMPLES_PER_THEME samples\n",
    "valid_themes = theme_counts[theme_counts >= MIN_SAMPLES_PER_THEME].index\n",
    "df = df[df['Theme'].isin(valid_themes)]\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"After filtering themes with < {MIN_SAMPLES_PER_THEME} samples:\")\n",
    "print(f\"Total samples: {len(df)}\")\n",
    "print(f\"Number of unique themes: {df['Theme'].nunique()}\")\n",
    "print(f\"\\nTheme distribution after filtering:\\n{df['Theme'].value_counts()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9c07e72",
   "metadata": {},
   "source": [
    "## Section 2: Train TF-IDF Vectorizer and Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c538773",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training samples: 27\n",
      "Testing samples: 7\n",
      "\n",
      "Model Accuracy: 0.4286\n",
      "\n",
      "Classification Report:\n",
      "                                   precision    recall  f1-score   support\n",
      "\n",
      "            AI / Machine Learning       0.00      0.00      0.00         1\n",
      "                    Cybersecurity       0.00      0.00      0.00         1\n",
      "Education & Workforce Development       0.43      1.00      0.60         3\n",
      "          Healthcare / Biomedical       0.00      0.00      0.00         1\n",
      "               Software / Systems       0.00      0.00      0.00         1\n",
      "\n",
      "                         accuracy                           0.43         7\n",
      "                        macro avg       0.09      0.20      0.12         7\n",
      "                     weighted avg       0.18      0.43      0.26         7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Encode labels\n",
    "label_encoder = LabelEncoder()\n",
    "df['label'] = label_encoder.fit_transform(df['Theme'])\n",
    "\n",
    "# Split data\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label'])\n",
    "\n",
    "print(f\"\\nTraining samples: {len(train_df)}\")\n",
    "print(f\"Testing samples: {len(test_df)}\")\n",
    "\n",
    "# Create and fit TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=5000, stop_words='english')\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(train_df['Title'])\n",
    "y_train = train_df['label']\n",
    "X_test_tfidf = tfidf_vectorizer.transform(test_df['Title'])\n",
    "y_test = test_df['label']\n",
    "\n",
    "# Train logistic regression model\n",
    "logistic_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logistic_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate model\n",
    "y_pred = logistic_model.predict(X_test_tfidf)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"\\nModel Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(\n",
    "    y_test,\n",
    "    y_pred,\n",
    "    target_names=label_encoder.classes_,\n",
    "    zero_division=0\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bc4f7a",
   "metadata": {},
   "source": [
    "## Section 3: Save Model Artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d6b1cde5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved logistic regression model to model_artifacts\\logistic_model.pkl\n",
      "✓ Saved TF-IDF vectorizer to model_artifacts\\tfidf_vectorizer.pkl\n",
      "✓ Saved label encoder to model_artifacts\\label_encoder.pkl\n",
      "\n",
      "✓ All model artifacts saved to 'model_artifacts/' directory\n",
      "Ready for use in the recommendation system!\n"
     ]
    }
   ],
   "source": [
    "# Create model_artifacts directory if it doesn't exist\n",
    "artifact_dir = 'model_artifacts'\n",
    "os.makedirs(artifact_dir, exist_ok=True)\n",
    "\n",
    "# Save the trained models and vectorizer\n",
    "model_path = os.path.join(artifact_dir, 'logistic_model.pkl')\n",
    "vectorizer_path = os.path.join(artifact_dir, 'tfidf_vectorizer.pkl')\n",
    "encoder_path = os.path.join(artifact_dir, 'label_encoder.pkl')\n",
    "\n",
    "with open(model_path, 'wb') as f:\n",
    "    pickle.dump(logistic_model, f)\n",
    "    print(f\"✓ Saved logistic regression model to {model_path}\")\n",
    "\n",
    "with open(vectorizer_path, 'wb') as f:\n",
    "    pickle.dump(tfidf_vectorizer, f)\n",
    "    print(f\"✓ Saved TF-IDF vectorizer to {vectorizer_path}\")\n",
    "\n",
    "with open(encoder_path, 'wb') as f:\n",
    "    pickle.dump(label_encoder, f)\n",
    "    print(f\"✓ Saved label encoder to {encoder_path}\")\n",
    "\n",
    "print(f\"\\n✓ All model artifacts saved to '{artifact_dir}/' directory\")\n",
    "print(f\"Ready for use in the recommendation system!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
